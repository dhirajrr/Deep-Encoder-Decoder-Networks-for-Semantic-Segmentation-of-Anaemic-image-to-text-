Here's a professional and comprehensive `README.md` for your GitHub repository based on your project poster and LinkedIn content:

---

# ğŸ”¬ Deep Encoder-Decoder Networks for Semantic Segmentation of Anaemic RBCs and Image Captioning

## ğŸ“Œ Project Overview

This project explores deep learning-based encoder-decoder architectures to solve two key tasks:

1. **Semantic segmentation** of anaemic Red Blood Cells (RBCs)
2. **Medical image captioning** (image-to-text generation)

We implemented and compared three models:

* **Baseline LSTM without Attention**
* **Bahdanau Attention-based RNN**
* **Transformer (Self-Attention)**

Each model was evaluated on medical imaging data using popular NLP metrics (BLEU, ROUGE, METEOR, SPICE) to assess caption quality and diagnostic relevance.

---

## ğŸ¯ Objectives

* Implement deep encoder-decoder models with varying attention mechanisms
* Train on a real-world RBC CELL dataset (microscopic images of anaemic vs. normal cells)
* Generate medical captions and compare model performance

---

## ğŸ§  Model Architectures

* ğŸ”¹ **LSTM (No Attention):** Uses fixed context from the last encoder state
* ğŸ”¹ **GRU with Bahdanau Attention:** Dynamically attends to relevant encoder outputs
* ğŸ”¹ **Transformer (Self-Attention):** Learns dependencies across the input using positional encoding and multi-head attention

All models are built using **TensorFlow/Keras** and trained on padded article-headline pairs.

---

## ğŸ“ Dataset Description

* **Type:** Microscopic images of Red Blood Cells (RBCs)
* **Format:** `.jpg` images
* **Classes:** `Anaemia`, `Normal`
* **Labels:** Inferred from folder names
* **Usage:** Binary classification & sequence-to-sequence medical caption generation

---

## ğŸ“Š Evaluation Metrics

| Metric | Score         |
| ------ | ------------- |
| BLEU   | 1.82 Ã— 10â»Â²Â³Â¹ |
| METEOR | 0.5           |
| SPICE  | 1.0           |

We also visualized:

* **Training Time Comparison**
* **BLEU & ROUGE Score Comparison**
* **Attention Mechanism Flowcharts**

---

## ğŸ“‰ Results & Insights

* âœ… Transformer model gave **best BLEU and ROUGE** scores.
* ğŸ¯ Attention-based models provided better contextual relevance in captions.
* ğŸ§  Demonstrated how attention improves performance in NLP + vision fusion tasks.

---

## ğŸ”§ Working Principle

* **No Attention:** Relies solely on the final encoder output.
* **Bahdanau Attention:** Dynamically computes attention weights over encoder states.
* **Self-Attention (Transformer):** Utilizes multi-head attention to capture long-range dependencies.

---

## ğŸ“„ Reference

Based on the paper:
**"Semantic Segmentation of Anaemic RBCs Using Multilevel Deep Convolutional Encoder-Decoder Network"**
M. Shahzad, A. I. Umar, S. H. Shirazi, and I. A. Shaikh
ğŸ“š *IEEE Access*, vol. 9, pp. 161326â€“161341, 2021
ğŸ”— [DOI: 10.1109/ACCESS.2021.3113768](https://doi.org/10.1109/ACCESS.2021.3113768)

---

## ğŸ§‘â€ğŸ’» Authors

* Dhiraj Rathod
* Sanke Nane
* Komal Katare
  **Mentor:** Prof. Diptee Chikmurge
  ğŸ“ MIT Academy of Engineering, Pune




## ğŸš€ How to Run

```bash
git clone https://github.com/your-username/rbc-captioning-transformer.git
cd rbc-captioning-transformer

# Create virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt

# Run training
python train_model.py --model transformer

# Evaluate and generate captions
python evaluate_model.py --input test_images/
```

---

## ğŸ—‚ï¸ Folder Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ anaemic/
â”‚   â”œâ”€â”€ normal/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ lstm_model.py
â”‚   â”œâ”€â”€ attention_model.py
â”‚   â””â”€â”€ transformer_model.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ preprocessing.py
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ project_poster.png
â”œâ”€â”€ train_model.py
â”œâ”€â”€ evaluate_model.py
â””â”€â”€ README.md
```

---
